{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tahap 3\n",
    "\n",
    "# ========================================\n",
    "# TAHAP 3 â€“ CASE RETRIEVAL (TF-IDF + IndoBERT)\n",
    "# ========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_id = stopwords.words('indonesian')\n",
    "\n",
    "# === Load Dataset\n",
    "df = pd.read_csv('/content/drive/MyDrive/Penalaran Komputer/CSV4/putusan_fidusia_cleaned_FINAL_BERSIH_FIX.csv')\n",
    "\n",
    "# === Ambil isi dokumen\n",
    "documents = df['text_pdf_cleaned'].astype(str).tolist()\n",
    "case_ids = df['nomor'].astype(str).tolist()\n",
    "\n",
    "# ----------------------------------------\n",
    "# ðŸ”¹ A. TF-IDF Retrieval\n",
    "# ----------------------------------------\n",
    "print(\"=== TF-IDF Retrieval ===\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=8000, stop_words=stopwords_id)\n",
    "tfidf_vectors = vectorizer.fit_transform(documents)\n",
    "\n",
    "def retrieve_tfidf(query: str, k: int = 5):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    sim_scores = cosine_similarity(query_vec, tfidf_vectors).flatten()\n",
    "    top_k_idx = sim_scores.argsort()[-k:][::-1]\n",
    "    return [(case_ids[i], sim_scores[i]) for i in top_k_idx]\n",
    "\n",
    "# Contoh uji coba\n",
    "query = \"Terdakwa menyewakan objek fidusia tanpa persetujuan\"\n",
    "tfidf_results = retrieve_tfidf(query)\n",
    "\n",
    "print(\"\\nTop-5 Hasil TF-IDF:\")\n",
    "for case_id, score in tfidf_results:\n",
    "    print(f\"Case ID: {case_id} â€” Similarity: {score:.4f}\")\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# ðŸ”¹ B. IndoBERT Embedding Retrieval\n",
    "# ----------------------------------------\n",
    "print(\"\\n=== IndoBERT Retrieval ===\")\n",
    "\n",
    "# Load IndoBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
    "model = AutoModel.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Hitung semua embedding dokumen\n",
    "bert_vectors = np.array([get_bert_embedding(doc) for doc in documents])\n",
    "\n",
    "def retrieve_bert(query: str, k: int = 5):\n",
    "    query_vec = get_bert_embedding(query).reshape(1, -1)\n",
    "    sim_scores = cosine_similarity(query_vec, bert_vectors).flatten()\n",
    "    top_k_idx = sim_scores.argsort()[-k:][::-1]\n",
    "    return [(case_ids[i], sim_scores[i]) for i in top_k_idx]\n",
    "\n",
    "# Contoh uji coba IndoBERT\n",
    "bert_results = retrieve_bert(query)\n",
    "\n",
    "print(\"\\nTop-5 Hasil IndoBERT:\")\n",
    "for case_id, score in bert_results:\n",
    "    print(f\"Case ID: {case_id} â€” Similarity: {score:.4f}\")\n",
    "\n",
    "\n",
    "klasifikasi nb svm\n",
    "\n",
    "# Gunakan label klasifikasi kasus\n",
    "labels = df['klasifikasi'].astype(str).tolist()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TF-IDF vector sudah kamu punya (tfidf_vectors)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tfidf_vectors, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "print(\"\\n=== Hasil Evaluasi SVM ===\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "print(\"\\n=== Hasil Evaluasi Naive Bayes ===\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_svm, average='weighted')\n",
    "\n",
    "eval_df = pd.DataFrame([{\n",
    "    'model': 'SVM',\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1\n",
    "}])\n",
    "\n",
    "eval_path = '/content/drive/MyDrive/Penalaran Komputer/data/eval/svm_fidusia_eval.csv'\n",
    "eval_df.to_csv(eval_path, index=False)\n",
    "print(f\"âœ… Evaluasi disimpan ke: {eval_path}\")\n",
    "\n",
    "\n",
    "display(eval_df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
